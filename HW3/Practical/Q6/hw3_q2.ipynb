{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs4rkP2Hq7Kd7TmPOhb+q9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### import the libraries"],"metadata":{"id":"RApuzdxnPxxg"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"POPiVUSJPsoz","executionInfo":{"status":"ok","timestamp":1744285310008,"user_tz":-210,"elapsed":321,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["### utility functions (no change is needed in this section)"],"metadata":{"id":"eW87sdDa-AAT"}},{"cell_type":"code","source":["def show_images(*images, titles=None):\n","    \"\"\"\n","    Displays multiple images using matplotlib.\n","\n","    Args:\n","        *images: Variable length image list to display.\n","        titles (list, optional): Titles for each subplot. Defaults to None.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    num_images = len(images)\n","    plt.figure(figsize=(15, 12))\n","\n","    for i, image in enumerate(images):\n","        plt.subplot(num_images, 1, i + 1)\n","        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","        if titles:\n","            plt.title(titles[i])\n","        plt.axis('off')\n","\n","    plt.show()"],"metadata":{"id":"71-HLma-9-0w","executionInfo":{"status":"ok","timestamp":1744285312350,"user_tz":-210,"elapsed":319,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def draw_corners_on_image(image, corners, neighborhood_size):\n","    \"\"\"\n","    Draws circles on the original image at detected corner locations.\n","\n","    Args:\n","        image (numpy.ndarray): Original image.\n","        corners (numpy.ndarray): Binary image with corner detections.\n","        neighborhood_size (int): Size of the neighborhood used for corner detection.\n","\n","    Returns:\n","        numpy.ndarray: Image with corners marked.\n","    \"\"\"\n","    height, width = image.shape[:2]\n","    offset = neighborhood_size // 2\n","\n","    for y in range(offset, height - offset):\n","        for x in range(offset, width - offset):\n","            if corners[y, x] == 255:\n","                cv2.circle(image, (x, y), 5, (255, 0, 0), -1)\n","\n","    return image"],"metadata":{"id":"DpN4IqY0-xnQ","executionInfo":{"status":"ok","timestamp":1744285314491,"user_tz":-210,"elapsed":7,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def draw_matches(img1, img2, kp1, kp2, matches):\n","    \"\"\"\n","    Draws matches between keypoints of two images.\n","\n","    Args:\n","        img1 (numpy.ndarray): First image.\n","        img2 (numpy.ndarray): Second image.\n","        kp1 (list): Keypoints in the first image.\n","        kp2 (list): Keypoints in the second image.\n","        matches (list): List of matched keypoints.\n","\n","    Returns:\n","        numpy.ndarray: Image with matches drawn.\n","    \"\"\"\n","    return cv2.drawMatches(\n","        img1, kp1,\n","        img2, kp2,\n","        matches, None,\n","        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n","    )"],"metadata":{"id":"P__67A0pDXQ_","executionInfo":{"status":"ok","timestamp":1744285316467,"user_tz":-210,"elapsed":5,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### image stitching"],"metadata":{"id":"QJ1On_TRRbHd"}},{"cell_type":"code","source":["def sift_feature_matching(img1, img2):\n","    \"\"\"\n","    Performs SIFT feature detection and matching between two images.\n","\n","    Args:\n","        img1 (numpy.ndarray): First grayscale image.\n","        img2 (numpy.ndarray): Second grayscale image.\n","\n","    Returns:\n","        tuple: Source points, destination points, and image with matches drawn.\n","    \"\"\"\n","    #############\n","    # YOUR CODE #\n","    #############\n","\n","    return src_pts, dst_pts, matched_img"],"metadata":{"id":"8PB3DEeQ6t__","executionInfo":{"status":"ok","timestamp":1744284952923,"user_tz":-210,"elapsed":340,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def ransac_homography(src_pts, dst_pts, num_iterations=2000, threshold=4):\n","    \"\"\"\n","    Computes the best homography matrix using RANSAC.\n","\n","    Args:\n","        src_pts (numpy.ndarray): Source points from the first image.\n","        dst_pts (numpy.ndarray): Destination points from the second image.\n","        num_iterations (int): Number of RANSAC iterations. Default is 2000.\n","        threshold (float): Distance threshold to determine inliers. Default is 4.\n","\n","    Returns:\n","        numpy.ndarray: Homography matrix.\n","    \"\"\"\n","    best_H = None\n","    max_inliers = 0\n","\n","    #############\n","    # YOUR CODE #\n","    #############\n","\n","    return best_H"],"metadata":{"id":"BrJMHKRVn1yH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def stitch_images(img1, img2, H):\n","    \"\"\"\n","    Stitches two images together using a homography matrix.\n","\n","    Args:\n","        img1 (numpy.ndarray): First image.\n","        img2 (numpy.ndarray): Second image.\n","        H (numpy.ndarray): Homography matrix.\n","\n","    Returns:\n","        numpy.ndarray: Stitched image.\n","    \"\"\"\n","    height, width = img2.shape[:2]\n","\n","    # Warp img1 to align with img2 using the homography matrix\n","\n","    #############\n","    # YOUR CODE #\n","    #############\n","\n","    return warped_img1"],"metadata":{"id":"hgH26hlgn4aF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load images\n","\n","left_path = # YOUR_PATH\n","right_path = # YOUR_PATH\n","\n","img1 = cv2.imread(right_path)\n","img2 = cv2.imread(left_path)\n","\n","# Convert images to grayscale\n","\n","#############\n","# YOUR CODE #\n","#############\n","\n","# Extract features and matching points\n","\n","#############\n","# YOUR CODE #\n","#############\n","\n","# Find the best homography using RANSAC\n","\n","#############\n","# YOUR CODE #\n","#############\n","\n","# Stitch images together\n","\n","#############\n","# YOUR CODE #\n","#############\n","\n","# Display the matched keypoints and the final stitched image\n","\n","#############\n","# YOUR CODE #\n","#############"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":983,"output_embedded_package_id":"1ArIRBxHHfKwUTAcNDJ-u-N1dj4M9ioJb"},"id":"oh9tu7YnGLhc","executionInfo":{"status":"ok","timestamp":1744284979472,"user_tz":-210,"elapsed":3645,"user":{"displayName":"Ali Fakhary","userId":"07970084108801316303"}},"outputId":"d4b6ba36-4d3a-485c-dc0b-fc1a8be3d1c8"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}